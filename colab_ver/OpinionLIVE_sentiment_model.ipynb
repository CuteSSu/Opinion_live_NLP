{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"OpinionLIVE_sentiment_model","provenance":[{"file_id":"1Hh63kIBAiBw3Hho--BvfdUWLu-ysMFF0","timestamp":1629622219982},{"file_id":"1IPkZo1Wd-DghIOK6gJpcb0Dv4_Gv2kXB","timestamp":1617802771913},{"file_id":"1dFC0FL-521m7CL_PSd8RLKq67jgTJVhL","timestamp":1615825089643}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HH-qFWpmtQ-q"},"source":["#드라이브 마운트"]},{"cell_type":"code","metadata":{"id":"nwx9FwBstTaO"},"source":["# 구글 드라이브 연동\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wGAdyjAdF0kd"},"source":["# Package 설치 & 데이터 받기\n"]},{"cell_type":"code","metadata":{"id":"vx2mHvhGFYBp"},"source":["try:\n","    import transformers, emoji, soynlp, pytorch_lightning\n","except:\n","    !pip install -U -q transformers emoji soynlp pytorch-lightning"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iKK-Y9a3F6vr"},"source":["import os\n","\n","if not os.path.exists('./nsmc'):\n","    !git clone https://github.com/e9t/nsmc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zYE7t_UNGiGO"},"source":["!head nsmc/ratings_train.txt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PLh_ziVCHwkH"},"source":["# 패키지 import & 기본 Args 설정"]},{"cell_type":"code","metadata":{"id":"Yb0113DUFE1k"},"source":["import os\n","import pandas as pd\n","\n","from pprint import pprint\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader, TensorDataset\n","from torch.optim.lr_scheduler import ExponentialLR\n","\n","from pytorch_lightning import LightningModule, Trainer, seed_everything\n","\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW\n","\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","import re\n","import emoji\n","from soynlp.normalizer import repeat_normalize"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dN1zqYeKH2JZ"},"source":["## 기본 학습 Arguments"]},{"cell_type":"code","metadata":{"id":"fPr2_vTPFuP0"},"source":["args = {\n","    'random_seed': 42, # Random Seed\n","    'pretrained_model': 'beomi/KcELECTRA-base',  # Transformers PLM name\n","    'pretrained_tokenizer': '',  # Optional, Transformers Tokenizer Name. Overrides `pretrained_model`\n","    'batch_size': 32,\n","    'lr': 5e-6,  # Starting Learning Rate\n","    'epochs': 1,  # Max Epochs\n","    'max_length': 150,  # Max Length input size\n","    'train_data_path': \"nsmc/ratings_train.txt\",  # Train Dataset file \n","    'val_data_path': \"nsmc/ratings_test.txt\",  # Validation Dataset file \n","    'test_mode': False,  # Test Mode enables `fast_dev_run`\n","    'optimizer': 'AdamW',  # AdamW vs AdamP\n","    'lr_scheduler': 'exp',  # ExponentialLR vs CosineAnnealingWarmRestarts\n","    'fp16': True,  # Enable train on FP16(if GPU)\n","    'tpu_cores': 0,  # Enable TPU with 1 core or 8 cores\n","    'cpu_workers': os.cpu_count(),\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h2AcwMYa3nmd"},"source":["# Model 만들기 with Pytorch Lightning"]},{"cell_type":"code","metadata":{"id":"ImupuGXDGq7b"},"source":["class Model(LightningModule):\n","    def __init__(self, **kwargs):\n","        super().__init__()\n","        self.save_hyperparameters() # 이 부분에서 self.hparams에 위 kwargs가 저장된다.\n","        \n","        self.clsfier = AutoModelForSequenceClassification.from_pretrained(self.hparams.pretrained_model)\n","        self.tokenizer = AutoTokenizer.from_pretrained(\n","            self.hparams.pretrained_tokenizer\n","            if self.hparams.pretrained_tokenizer\n","            else self.hparams.pretrained_model\n","        )\n","\n","    def forward(self, **kwargs):\n","        return self.clsfier(**kwargs)\n","\n","    def step(self, batch, batch_idx):\n","        data, labels = batch\n","        output = self(input_ids=data, labels=labels)\n","\n","        # Transformers 4.0.0+\n","        loss = output.loss\n","        logits = output.logits\n","\n","        preds = logits.argmax(dim=-1)\n","\n","        y_true = list(labels.cpu().numpy())\n","        y_pred = list(preds.cpu().numpy())\n","\n","        return {\n","            'loss': loss,\n","            'y_true': y_true,\n","            'y_pred': y_pred,\n","        }\n","\n","    def training_step(self, batch, batch_idx):\n","        return self.step(batch, batch_idx)\n","\n","    def validation_step(self, batch, batch_idx):\n","        return self.step(batch, batch_idx)\n","\n","    def epoch_end(self, outputs, state='train'):\n","        loss = torch.tensor(0, dtype=torch.float)\n","        for i in outputs:\n","            loss += i['loss'].cpu().detach()\n","        loss = loss / len(outputs)\n","\n","        y_true = []\n","        y_pred = []\n","        for i in outputs:\n","            y_true += i['y_true']\n","            y_pred += i['y_pred']\n","        \n","        acc = accuracy_score(y_true, y_pred)\n","        prec = precision_score(y_true, y_pred)\n","        rec = recall_score(y_true, y_pred)\n","        f1 = f1_score(y_true, y_pred)\n","\n","        self.log(state+'_loss', float(loss), on_epoch=True, prog_bar=True)\n","        self.log(state+'_acc', acc, on_epoch=True, prog_bar=True)\n","        self.log(state+'_precision', prec, on_epoch=True, prog_bar=True)\n","        self.log(state+'_recall', rec, on_epoch=True, prog_bar=True)\n","        self.log(state+'_f1', f1, on_epoch=True, prog_bar=True)\n","        print(f'[Epoch {self.trainer.current_epoch} {state.upper()}] Loss: {loss}, Acc: {acc}, Prec: {prec}, Rec: {rec}, F1: {f1}')\n","        return {'loss': loss}\n","    \n","    def training_epoch_end(self, outputs):\n","        self.epoch_end(outputs, state='train')\n","\n","    def validation_epoch_end(self, outputs):\n","        self.epoch_end(outputs, state='val')\n","\n","    def configure_optimizers(self):\n","        if self.hparams.optimizer == 'AdamW':\n","            optimizer = AdamW(self.parameters(), lr=self.hparams.lr)\n","        elif self.hparams.optimizer == 'AdamP':\n","            from adamp import AdamP\n","            optimizer = AdamP(self.parameters(), lr=self.hparams.lr)\n","        else:\n","            raise NotImplementedError('Only AdamW and AdamP is Supported!')\n","        if self.hparams.lr_scheduler == 'cos':\n","            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=1, T_mult=2)\n","        elif self.hparams.lr_scheduler == 'exp':\n","            scheduler = ExponentialLR(optimizer, gamma=0.5)\n","        else:\n","            raise NotImplementedError('Only cos and exp lr scheduler is Supported!')\n","        return {\n","            'optimizer': optimizer,\n","            'scheduler': scheduler,\n","        }\n","\n","    def read_data(self, path):\n","        if path.endswith('xlsx'):\n","            return pd.read_excel(path)\n","        elif path.endswith('csv'):\n","            return pd.read_csv(path)\n","        elif path.endswith('tsv') or path.endswith('txt'):\n","            return pd.read_csv(path, sep='\\t')\n","        else:\n","            raise NotImplementedError('Only Excel(xlsx)/Csv/Tsv(txt) are Supported')\n","\n","    def clean(self, x):\n","        emojis = ''.join(emoji.UNICODE_EMOJI.keys())\n","        pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-힣{emojis}]+')\n","        url_pattern = re.compile(\n","            r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n","        x = pattern.sub(' ', x)\n","        x = url_pattern.sub('', x)\n","        x = x.strip()\n","        x = repeat_normalize(x, num_repeats=2)\n","        return x\n","\n","    def encode(self, x, **kwargs):\n","        return self.tokenizer.encode(\n","            self.clean(str(x)),\n","            padding='max_length',\n","            max_length=self.hparams.max_length,\n","            truncation=True,\n","            **kwargs,\n","        )\n","\n","    def preprocess_dataframe(self, df):\n","        df['document'] = df['document'].map(self.encode)\n","        return df\n","\n","    def dataloader(self, path, shuffle=False):\n","        df = self.read_data(path)\n","        df = self.preprocess_dataframe(df)\n","\n","        dataset = TensorDataset(\n","            torch.tensor(df['document'].to_list(), dtype=torch.long),\n","            torch.tensor(df['label'].to_list(), dtype=torch.long),\n","        )\n","        return DataLoader(\n","            dataset,\n","            batch_size=self.hparams.batch_size * 1 if not self.hparams.tpu_cores else self.hparams.tpu_cores,\n","            shuffle=shuffle,\n","            num_workers=self.hparams.cpu_workers,\n","        )\n","\n","    def train_dataloader(self):\n","        return self.dataloader(self.hparams.train_data_path, shuffle=True)\n","\n","    def val_dataloader(self):\n","        return self.dataloader(self.hparams.val_data_path, shuffle=False)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_FteKzZ67cyj"},"source":["from pytorch_lightning.callbacks import ModelCheckpoint\n","\n","checkpoint_callback = ModelCheckpoint(\n","    filename='epoch{epoch}-val_acc{val_acc:.4f}',\n","    monitor='val_acc',\n","    save_top_k=3,\n","    mode='max',\n","    auto_insert_metric_name=False,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zBsvcdxySCqd"},"source":["# 학습"]},{"cell_type":"code","metadata":{"id":"qu1QkSZsHo8x"},"source":["print(\"Using PyTorch Ver\", torch.__version__)\n","print(\"Fix Seed:\", args['random_seed'])\n","seed_everything(args['random_seed'])\n","model = Model(**args)\n","\n","print(\":: Start Training ::\")\n","trainer = Trainer(\n","    callbacks=[checkpoint_callback],\n","    max_epochs=args['epochs'],\n","    fast_dev_run=args['test_mode'],\n","    num_sanity_val_steps=None if args['test_mode'] else 0,\n","    # For GPU Setup\n","    deterministic=torch.cuda.is_available(),\n","    gpus=[0] if torch.cuda.is_available() else None,  # 0번 idx GPU  사용\n","    precision=16 if args['fp16'] and torch.cuda.is_available() else 32,\n","    # For TPU Setup\n","    # tpu_cores=args['tpu_cores'] if args['tpu_cores'] else None,\n",")\n","trainer.fit(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cyczos82ept3"},"source":["# Inference"]},{"cell_type":"code","metadata":{"id":"8mdp3SK2etM-"},"source":["from glob import glob\n","\n","latest_ckpt = sorted(glob('./lightning_logs/version_0/checkpoints/*.ckpt'))[-1]\n","latest_ckpt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SOMT9Ublj_1G"},"source":["model = Model.load_from_checkpoint(latest_ckpt)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DqlCK83Je8JL"},"source":["def infer(x):\n","    return torch.softmax(\n","        model(**model.tokenizer(x, return_tensors='pt')\n","    ).logits, dim=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"feoKN8OWfB86"},"source":["infer('노잼')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ip5R5K4-tja_"},"source":["#모델저장"]},{"cell_type":"code","metadata":{"id":"mOghHBe2tmfA"},"source":["import joblib\n","joblib.dump(model, '/content/drive/MyDrive/opinionlive/model_pkl/SA_model.pkl')"],"execution_count":null,"outputs":[]}]}